{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing The Essential Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, MeanAbsoluteError\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Add, Lambda, LeakyReLU, Flatten, Dense\n",
    "from tensorflow.python.keras.layers import PReLU\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "\n",
    "from datasets.div2k.parameters import Div2kParameters \n",
    "from datasets.div2k.loader import create_training_and_validation_datasets\n",
    "from utils.normalization import normalize_m11, normalize_01, denormalize_m11\n",
    "from utils.dataset_mappings import random_crop, random_flip, random_rotate, random_lr_jpeg_noise\n",
    "from utils.metrics import psnr_metric\n",
    "from utils.config import config\n",
    "from utils.callbacks import SaveCustomCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing The Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Link - https://data.vision.ee.ethz.ch/cvl/DIV2K/\n",
    "# http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\n",
    "# https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_bicubic_X4.zip\n",
    "# http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
    "# http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
    "\n",
    "dataset_key = \"bicubic_x4\"\n",
    "\n",
    "data_path = config.get(\"data_path\", \"\") \n",
    "\n",
    "div2k_folder = os.path.abspath(os.path.join(data_path, \"div2k\"))\n",
    "\n",
    "dataset_parameters = Div2kParameters(dataset_key, save_data_directory=div2k_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_crop_size = 96\n",
    "\n",
    "train_mappings = [\n",
    "    lambda lr, hr: random_crop(lr, hr, hr_crop_size=hr_crop_size, scale=dataset_parameters.scale), \n",
    "    random_flip, \n",
    "    random_rotate, \n",
    "    random_lr_jpeg_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = create_training_and_validation_datasets(dataset_parameters, train_mappings)\n",
    "\n",
    "valid_dataset_subset = valid_dataset.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct The SRRESNET Generator Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsamples_per_scale = {\n",
    "    2: 1,\n",
    "    4: 2,\n",
    "    8: 3\n",
    "}\n",
    "\n",
    "\n",
    "pretrained_srresnet_models = {\n",
    "    \"srresnet_bicubic_x4\": {\n",
    "        \"url\": \"https://image-super-resolution-weights.s3.af-south-1.amazonaws.com/srresnet_bicubic_x4/generator.h5\",\n",
    "        \"scale\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def pixel_shuffle(scale):\n",
    "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
    "\n",
    "\n",
    "def upsample(x_in, num_filters):\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x_in)\n",
    "    x = Lambda(pixel_shuffle(scale=2))(x)\n",
    "    return PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "\n",
    "def residual_block(block_input, num_filters, momentum=0.8):\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(block_input)\n",
    "    x = BatchNormalization(momentum=momentum)(x)\n",
    "    x = PReLU(shared_axes=[1, 2])(x)\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=momentum)(x)\n",
    "    x = Add()([block_input, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_srresnet(scale=4, num_filters=64, num_res_blocks=16):\n",
    "    if scale not in upsamples_per_scale:\n",
    "        raise ValueError(f\"available scales are: {upsamples_per_scale.keys()}\")\n",
    "\n",
    "    num_upsamples = upsamples_per_scale[scale]\n",
    "\n",
    "    lr = Input(shape=(None, None, 3))\n",
    "    x = Lambda(normalize_01)(lr)\n",
    "\n",
    "    x = Conv2D(num_filters, kernel_size=9, padding='same')(x)\n",
    "    x = x_1 = PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "    for _ in range(num_res_blocks):\n",
    "        x = residual_block(x, num_filters)\n",
    "\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_1, x])\n",
    "\n",
    "    for _ in range(num_upsamples):\n",
    "        x = upsample(x, num_filters * 4)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=9, padding='same', activation='tanh')(x)\n",
    "    sr = Lambda(denormalize_m11)(x)\n",
    "\n",
    "    return Model(lr, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_srresnet(scale=dataset_parameters.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir=f'./ckpt/sr_resnet_{dataset_key}'\n",
    "\n",
    "learning_rate=1e-4\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                 epoch=tf.Variable(0),\n",
    "                                 psnr=tf.Variable(0.0),\n",
    "                                 optimizer=Adam(learning_rate),\n",
    "                                 model=generator)\n",
    "\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "                                                directory=checkpoint_dir,\n",
    "                                                max_to_keep=3)\n",
    "\n",
    "if checkpoint_manager.latest_checkpoint:\n",
    "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "    print(f'Model restored from checkpoint at step {checkpoint.step.numpy()} with validation PSNR {checkpoint.psnr.numpy()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_directory = f\"weights/srresnet_{dataset_key}\"\n",
    "os.makedirs(weights_directory, exist_ok=True)\n",
    "weights_file = f'{weights_directory}/generator.h5'\n",
    "checkpoint.model.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct The Discriminator Model and The SRGAN Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_block(x_in, num_filters, strides=1, batchnorm=True, momentum=0.8):\n",
    "    x = Conv2D(num_filters, kernel_size=3, strides=strides, padding='same')(x_in)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization(momentum=momentum)(x)\n",
    "    return LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\n",
    "def build_discriminator(hr_crop_size):\n",
    "    x_in = Input(shape=(hr_crop_size, hr_crop_size, 3))\n",
    "    x = Lambda(normalize_m11)(x_in)\n",
    "\n",
    "    x = discriminator_block(x, 64, batchnorm=False)\n",
    "    x = discriminator_block(x, 64, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, 128)\n",
    "    x = discriminator_block(x, 128, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, 256)\n",
    "    x = discriminator_block(x, 256, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, 512)\n",
    "    x = discriminator_block(x, 512, strides=2)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(x_in, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_srresnet(scale=dataset_parameters.scale)\n",
    "generator.load_weights(weights_file)\n",
    "discriminator = build_discriminator(hr_crop_size=hr_crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_5_4 = 20\n",
    "vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
    "perceptual_model = Model(vgg.input, vgg.layers[layer_5_4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_entropy = BinaryCrossentropy()\n",
    "mean_squared_error = MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=PiecewiseConstantDecay(boundaries=[100000], values=[1e-4, 1e-5])\n",
    "generator_optimizer = Adam(learning_rate=learning_rate)\n",
    "discriminator_optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "srgan_checkpoint_dir=f'./ckpt/srgan_{dataset_key}'\n",
    "\n",
    "srgan_checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                       psnr=tf.Variable(0.0),\n",
    "                                       generator_optimizer=Adam(learning_rate),\n",
    "                                       discriminator_optimizer=Adam(learning_rate),\n",
    "                                       generator=generator,\n",
    "                                       discriminator=discriminator)\n",
    "\n",
    "srgan_checkpoint_manager = tf.train.CheckpointManager(checkpoint=srgan_checkpoint,\n",
    "                                                directory=srgan_checkpoint_dir,\n",
    "                                                max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if srgan_checkpoint_manager.latest_checkpoint:\n",
    "    srgan_checkpoint.restore(srgan_checkpoint_manager.latest_checkpoint)\n",
    "    print(f'Model restored from checkpoint at step {srgan_checkpoint.step.numpy()} with validation PSNR {srgan_checkpoint.psnr.numpy()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(lr, hr):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        lr = tf.cast(lr, tf.float32)\n",
    "        hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "        sr = srgan_checkpoint.generator(lr, training=True)\n",
    "\n",
    "        hr_output = srgan_checkpoint.discriminator(hr, training=True)\n",
    "        sr_output = srgan_checkpoint.discriminator(sr, training=True)\n",
    "\n",
    "        con_loss = calculate_content_loss(hr, sr)\n",
    "        gen_loss = calculate_generator_loss(sr_output)\n",
    "        perc_loss = con_loss + 0.001 * gen_loss\n",
    "        disc_loss = calculate_discriminator_loss(hr_output, sr_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(perc_loss, srgan_checkpoint.generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, srgan_checkpoint.discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, srgan_checkpoint.generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, srgan_checkpoint.discriminator.trainable_variables))\n",
    "\n",
    "    return perc_loss, disc_loss\n",
    "\n",
    "@tf.function\n",
    "def calculate_content_loss(hr, sr):\n",
    "    sr = preprocess_input(sr)\n",
    "    hr = preprocess_input(hr)\n",
    "    sr_features = perceptual_model(sr) / 12.75\n",
    "    hr_features = perceptual_model(hr) / 12.75\n",
    "    return mean_squared_error(hr_features, sr_features)\n",
    "\n",
    "def calculate_generator_loss(sr_out):\n",
    "    return binary_cross_entropy(tf.ones_like(sr_out), sr_out)\n",
    "\n",
    "def calculate_discriminator_loss(hr_out, sr_out):\n",
    "    hr_loss = binary_cross_entropy(tf.ones_like(hr_out), hr_out)\n",
    "    sr_loss = binary_cross_entropy(tf.zeros_like(sr_out), sr_out)\n",
    "    return hr_loss + sr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/200000, psnr = 13.666447639465332, perceptual loss = 0.1845, discriminator loss = 0.4422 (1880.05s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3d9002dd1929>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0msrgan_checkpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0msrgan_checkpoint_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensors\\lib\\site-packages\\tensorflow\\python\\training\\checkpoint_management.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, checkpoint_number, check_interval)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintegral_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m       checkpoint_number = training_util.global_step(\n\u001b[1;32m--> 805\u001b[1;33m           sess=session, global_step_tensor=checkpoint_number)\n\u001b[0m\u001b[0;32m    806\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s-%d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensors\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py\u001b[0m in \u001b[0;36mglobal_step\u001b[1;34m(sess, global_step_tensor)\u001b[0m\n\u001b[0;32m     65\u001b[0m   \"\"\"\n\u001b[0;32m     66\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensors\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    616\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    620\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensors\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensors\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensors\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensors\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   3927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3928\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 3929\u001b[1;33m         _ctx, \"Identity\", name, input)\n\u001b[0m\u001b[0;32m   3930\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3931\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "perceptual_loss_metric = Mean()\n",
    "discriminator_loss_metric = Mean()\n",
    "\n",
    "step = srgan_checkpoint.step.numpy()\n",
    "steps = 200000\n",
    "\n",
    "monitor_folder = f\"monitor_training/srgan_{dataset_key}\"\n",
    "os.makedirs(monitor_folder, exist_ok=True)\n",
    "\n",
    "now = time.perf_counter()\n",
    "\n",
    "for lr, hr in train_dataset.take(steps - step):\n",
    "    srgan_checkpoint.step.assign_add(1)\n",
    "    step = srgan_checkpoint.step.numpy()\n",
    "\n",
    "    perceptual_loss, discriminator_loss = train_step(lr, hr)\n",
    "    perceptual_loss_metric(perceptual_loss)\n",
    "    discriminator_loss_metric(discriminator_loss)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        psnr_values = []\n",
    "        \n",
    "        for lr, hr in valid_dataset_subset:\n",
    "            sr = srgan_checkpoint.generator.predict(lr)[0]\n",
    "            sr = tf.clip_by_value(sr, 0, 255)\n",
    "            sr = tf.round(sr)\n",
    "            sr = tf.cast(sr, tf.uint8)\n",
    "            \n",
    "            psnr_value = psnr_metric(hr, sr)[0]\n",
    "            psnr_values.append(psnr_value)\n",
    "            psnr = tf.reduce_mean(psnr_values)\n",
    "            \n",
    "        image = Image.fromarray(sr.numpy())\n",
    "        image.save(f\"{monitor_folder}/{step}.png\" )\n",
    "        \n",
    "        duration = time.perf_counter() - now\n",
    "        \n",
    "        now = time.perf_counter()\n",
    "        \n",
    "        print(f'{step}/{steps}, psnr = {psnr}, perceptual loss = {perceptual_loss_metric.result():.4f}, discriminator loss = {discriminator_loss_metric.result():.4f} ({duration:.2f}s)')\n",
    "        \n",
    "        perceptual_loss_metric.reset_states()\n",
    "        discriminator_loss_metric.reset_states()\n",
    "        \n",
    "        srgan_checkpoint.psnr.assign(psnr)\n",
    "        srgan_checkpoint_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_directory = f\"weights/srgan_{dataset_key}\"\n",
    "os.makedirs(weights_directory, exist_ok=True)\n",
    "weights_file = f'{weights_directory}/generator.h5'\n",
    "srgan_checkpoint.generator.save_weights(weights_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
